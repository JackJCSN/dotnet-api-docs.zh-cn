<Type Name="RecognizerState" FullName="System.Speech.Recognition.RecognizerState">
  <Metadata><Meta Name="ms.openlocfilehash" Value="05957d7ff57ae9219224c435b8197206b4d7cbd4" /><Meta Name="ms.sourcegitcommit" Value="f1d16425528e237257ca3b58eb49217a514849ea" /><Meta Name="ms.translationtype" Value="MT" /><Meta Name="ms.contentlocale" Value="zh-CN" /><Meta Name="ms.lasthandoff" Value="04/24/2019" /><Meta Name="ms.locfileid" Value="64095721" /></Metadata><TypeSignature Language="C#" Value="public enum RecognizerState" />
  <TypeSignature Language="ILAsm" Value=".class public auto ansi sealed RecognizerState extends System.Enum" />
  <TypeSignature Language="DocId" Value="T:System.Speech.Recognition.RecognizerState" />
  <TypeSignature Language="VB.NET" Value="Public Enum RecognizerState" />
  <TypeSignature Language="C++ CLI" Value="public enum class RecognizerState" />
  <TypeSignature Language="F#" Value="type RecognizerState = " />
  <AssemblyInfo>
    <AssemblyName>System.Speech</AssemblyName>
    <AssemblyVersion>3.0.0.0</AssemblyVersion>
    <AssemblyVersion>4.0.0.0</AssemblyVersion>
  </AssemblyInfo>
  <Base>
    <BaseTypeName>System.Enum</BaseTypeName>
  </Base>
  <Docs>
    <summary>枚举识别器状态的值。</summary>
    <remarks>
      <format type="text/markdown"><![CDATA[  
  
## Remarks  
 <xref:System.Speech.Recognition.RecognizerState> 封装为客户端使用的默认语音识别引擎的运行状态<xref:System.Speech.Recognition.SpeechRecognizer>来访问 Windows 桌面语音识别技术服务。  
  
 应用程序可以获取作为桌面识别引擎的当前状态<xref:System.Speech.Recognition.RecognizerState>通过查询对象<xref:System.Speech.Recognition.SpeechRecognizer.State%2A>属性上的<xref:System.Speech.Recognition.SpeechRecognizer>实例。  若要获取桌面识别引擎的状态发生更改后，应用程序可以查询<xref:System.Speech.Recognition.StateChangedEventArgs.RecognizerState%2A>的属性<xref:System.Speech.Recognition.StateChangedEventArgs>对象传递给处理程序<xref:System.Speech.Recognition.SpeechRecognizer.StateChanged>事件。  
  
> [!NOTE]
>  <xref:System.Speech.Recognition.SpeechRecognitionEngine> 在进程中运行的实例和其运行状态是由应用程序的控制。 因此，<xref:System.Speech.Recognition.SpeechRecognitionEngine>不包含一个属性来返回<xref:System.Speech.Recognition.RecognizerState>对象。  
  
 桌面语音识别服务器的状态是只读的属性，并不能以编程方式控制。 用户可以更改共享的语音识别器的状态使用语音识别用户界面 (UI) 或通过**语音识别**成员的 Windows**控制面板**。  
  
 这两个**上**并**睡眠**语音识别 UI 中的设置对应于`Listening`状态。 **关闭**语音识别 UI 中的设置对应于已停止。  
  
 <xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A> 是会影响共享的语音识别引擎来接收和处理语音输入的准备情况的其他属性。 可以使用<xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A>来控制共享的语音识别引擎的语法是否识别的活动。 但是，更改<xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A>属性不起任何作用<xref:System.Speech.Recognition.RecognizerState>属性。  
  
 说明、 受支持的区域性和音频格式和识别引擎名称等信息封装在<xref:System.Speech.Recognition.RecognizerInfo>类型。  
  
   
  
## Examples  
 在下面的示例中，应用程序将显示在其实现中的处理程序的识别器的状态<xref:System.Speech.Recognition.SpeechRecognizer.StateChanged>事件。  
  
```  
  
_recognizer.StateChanged +=  
    delegate(object sender, StateChangedEventArgs eventArgs) {  
        _recognizerStateLabel.Text = "Speech Recognizer State: " + eventArgs.RecognizerState.ToString();  
    };  
  
```  
  
 ]]></format>
    </remarks>
    <altmember cref="P:System.Speech.Recognition.StateChangedEventArgs.RecognizerState" />
    <altmember cref="T:System.Speech.Recognition.SpeechRecognizer" />
    <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.Enabled" />
    <altmember cref="P:System.Speech.Recognition.SpeechRecognizer.State" />
    <altmember cref="T:System.Speech.Recognition.StateChangedEventArgs" />
    <altmember cref="E:System.Speech.Recognition.SpeechRecognizer.StateChanged" />
  </Docs>
  <Members>
    <Member MemberName="Listening">
      <MemberSignature Language="C#" Value="Listening" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype System.Speech.Recognition.RecognizerState Listening = int32(1)" />
      <MemberSignature Language="DocId" Value="F:System.Speech.Recognition.RecognizerState.Listening" />
      <MemberSignature Language="VB.NET" Value="Listening" />
      <MemberSignature Language="C++ CLI" Value="Listening" />
      <MemberSignature Language="F#" Value="Listening = 1" Usage="System.Speech.Recognition.RecognizerState.Listening" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.RecognizerState</ReturnType>
      </ReturnValue>
      <MemberValue>1</MemberValue>
      <Docs>
        <summary>识别引擎可接收和分析音频输入。</summary>
      </Docs>
    </Member>
    <Member MemberName="Stopped">
      <MemberSignature Language="C#" Value="Stopped" />
      <MemberSignature Language="ILAsm" Value=".field public static literal valuetype System.Speech.Recognition.RecognizerState Stopped = int32(0)" />
      <MemberSignature Language="DocId" Value="F:System.Speech.Recognition.RecognizerState.Stopped" />
      <MemberSignature Language="VB.NET" Value="Stopped" />
      <MemberSignature Language="C++ CLI" Value="Stopped" />
      <MemberSignature Language="F#" Value="Stopped = 0" Usage="System.Speech.Recognition.RecognizerState.Stopped" />
      <MemberType>Field</MemberType>
      <AssemblyInfo>
        <AssemblyName>System.Speech</AssemblyName>
        <AssemblyVersion>3.0.0.0</AssemblyVersion>
        <AssemblyVersion>4.0.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Speech.Recognition.RecognizerState</ReturnType>
      </ReturnValue>
      <MemberValue>0</MemberValue>
      <Docs>
        <summary>识别引擎不接收或分析音频输入。</summary>
      </Docs>
    </Member>
  </Members>
</Type>